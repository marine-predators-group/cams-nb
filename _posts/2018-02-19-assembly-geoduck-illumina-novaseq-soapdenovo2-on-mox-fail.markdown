---
author: kubu4
comments: true
date: 2018-02-19 17:21:19+00:00
layout: post
link: http://onsnetwork.org/kubu4/2018/02/19/assembly-geoduck-illumina-novaseq-soapdenovo2-on-mox-fail/
slug: assembly-geoduck-illumina-novaseq-soapdenovo2-on-mox-fail
title: Assembly - Geoduck Illumina NovaSeq SOAPdenovo2 on Mox (FAIL)
wordpress_id: 3099
author:
- kubu4
categories:
- Geoduck Genome Sequencing
tags:
- assembly
- geoduck
- mox
- NovaSeq
- Panopea generosa
- SOAPdenovo2
---

Trying to get the NovaSeq data assembled using SOAPdenovo2 on the Mox HPC node we have and it will not work.

Tried a couple of times and it hasn't run successfully. Here are links to the files used on Mox (including the batch script and slurm output files). I made slight changes to the formatting of the batch script because I thought there was something wrong. Specifically, the [slurm output file in the 20180215 runs](http://owl.fish.washington.edu/Athaliana/20180215_soapdenovo2_novaseq_geoduck/slurm-134981.out) does not accurately reflect the command I issued (i.e. `1> ass.log` is command, but slurm shows `> ass.log`).





  * [20180215_soapdenovo2_novaseq_geoduck](http://owl.fish.washington.edu/Athaliana/20180215_soapdenovo2_novaseq_geoduck/): This failed for no obvious reason. [The slurm output file](http://owl.fish.washington.edu/Athaliana/20180215_soapdenovo2_novaseq_geoduck/slurm-134981.out) simply indicates the job was killed and the [SOAPdenov2 error log](http://owl.fish.washington.edu/Athaliana/20180215_soapdenovo2_novaseq_geoduck/ass.err) doesn't contain any info regarding why the job failed.



  * [20180218_soapdenovo2_novaseq_geoduck/](http://owl.fish.washington.edu/Athaliana/20180218_soapdenovo2_novaseq_geoduck/): This failed because there wasn't enough memory(!!??) - see below for more info.






NOTE: In the 20180218 run, I have excluded transferring the core dump file due to its crazy size:

![](http://owl.fish.washington.edu/Athaliana/20180218_mox_geo_novaseq_fail_01.png)

Here's the [error log generated by SOAPdenovo2 in the 20180218 run](http://owl.fish.washington.edu/Athaliana/20180218_soapdenovo2_novaseq_geoduck/ass.err) (the last line is all you really need to see, though):

[code lang=text]
Version 2.04: released on July 13th, 2012
Compile May 10 2017 12:50:52

********************
Pregraph
********************

Parameters: pregraph -s /gscratch/scrubbed/samwhite/20180218_soapdenovo2_novaseq_geoduck/soap_config -K 117 -p 24 -o /gscratch/scrubbed/samwhite/20180218_soapdenovo2_novaseq_geoduck/ 

In /gscratch/scrubbed/samwhite/20180218_soapdenovo2_novaseq_geoduck/soap_config, 1 lib(s), maximum read length 150, maximum name length 256.

24 thread(s) initialized.
Import reads from file:
 /gscratch/scrubbed/samwhite/20180129_trimmed_again/AD002_S9_L001_R1_001_val_1_val_1.fq.gz
Import reads from file:
 /gscratch/scrubbed/samwhite/20180129_trimmed_again/AD002_S9_L001_R2_001_val_2_val_2.fq.gz
--- 100000000th reads.
--- 200000000th reads.
--- 300000000th reads.
Import reads from file:
 /gscratch/scrubbed/samwhite/20180129_trimmed_again/AD002_S9_L002_R1_001_val_1_val_1.fq.gz
Import reads from file:
 /gscratch/scrubbed/samwhite/20180129_trimmed_again/AD002_S9_L002_R2_001_val_2_val_2.fq.gz
--- 400000000th reads.
--- 500000000th reads.
--- 600000000th reads.
--- 700000000th reads.
Import reads from file:
 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR005_S4_L001_R1_001_val_1_val_1.fq.gz
Import reads from file:
 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR005_S4_L001_R2_001_val_2_val_2.fq.gz
Import reads from file:
 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR005_S4_L002_R1_001_val_1_val_1.fq.gz
Import reads from file:
 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR005_S4_L002_R2_001_val_2_val_2.fq.gz
Import reads from file:
 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR006_S3_L001_R1_001_val_1_val_1.fq.gz
Import reads from file:
 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR006_S3_L001_R2_001_val_2_val_2.fq.gz
Import reads from file:
 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR006_S3_L002_R1_001_val_1_val_1.fq.gz
Import reads from file:
 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR006_S3_L002_R2_001_val_2_val_2.fq.gz
Import reads from file:
 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR012_S1_L001_R1_001_val_1_val_1.fq.gz
Import reads from file:
 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR012_S1_L001_R2_001_val_2_val_2.fq.gz
Import reads from file:
 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR012_S1_L002_R1_001_val_1_val_1.fq.gz
Import reads from file:
 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR012_S1_L002_R2_001_val_2_val_2.fq.gz
Import reads from file:
 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR013_AD013_S2_L001_R1_001_val_1_val_1.fq.gz
Import reads from file:
 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR013_AD013_S2_L001_R2_001_val_2_val_2.fq.gz
--- 800000000th reads.
--- 900000000th reads.
-- Out of memory --

[/code]

I guess I'll explore some other options for assembling these? I'm having a difficult time accepting that 500GB of RAM is insufficient, but that seems to be the case. Ouch.
